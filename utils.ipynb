{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import copy\n",
    "import itertools\n",
    "import random\n",
    "from OpenNE import  node2vec\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "import OpenNE.graph as og\n",
    "import csv\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "def read_for_OpenNE(filename):\n",
    "    G = og.Graph()\n",
    "    G.read_edgelist(filename=filename)\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_graph(input_edgelist,fu_edgelist, seed, testing_ratio=0.2):\n",
    "    G1 = nx.read_edgelist(input_edgelist)\n",
    "    G0 = nx.read_weighted_edgelist(fu_edgelist)\n",
    "    node_num1, edge_num1 = len(G1.nodes), len(G1.edges)\n",
    "    print('Original Graph: nodes:', node_num1, 'edges:', edge_num1)\n",
    "    G_train = copy.deepcopy(G1)\n",
    "    G_train.remove_nodes_from(list(nx.isolates(G_train)))\n",
    "    train_graph_filename = 'graph_train.edgelist'\n",
    "    nx.write_edgelist(G_train, train_graph_filename, data=False)\n",
    "    node_num1, edge_num1 = len(G_train.nodes), len(G_train.edges)\n",
    "    print('delt Graph: nodes:', node_num1, 'edges:', edge_num1)\n",
    "    L1 = list(G_train.nodes())\n",
    "    L0 = list(G0.nodes())\n",
    "    for i in range(len(L0)):\n",
    "        if L0[i] in L1:\n",
    "            continue\n",
    "        else:\n",
    "            G0.remove_node(L0[i])\n",
    "    G0.remove_nodes_from(list(nx.isolates(G0)))\n",
    "    node_num0, edge_num0 = len(G0.nodes), len(G0.edges)\n",
    "    num = edge_num1-edge_num0\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(itertools.combinations(L1, 2))\n",
    "    G.remove_edges_from(G_train.edges())\n",
    "    G.remove_edges_from(G0.edges())\n",
    "    random.seed(seed)\n",
    "    for edge in G.edges:\n",
    "        node_u, node_v = edge\n",
    "        if (G.degree(node_u) > 10 and G.degree(node_v) > 10):\n",
    "            G.remove_edge(node_u, node_v)\n",
    "    neg_edges = random.sample(G.edges, num)\n",
    "    G0.add_edges_from(neg_edges)\n",
    "    node_num0, edge_num0 = len(G0.nodes), len(G0.edges)\n",
    "    testing_edges_num = int(len(G_train.edges) * testing_ratio)\n",
    "    random.seed(seed)\n",
    "    testing_pos_edges = random.sample(G_train.edges, testing_edges_num)\n",
    "    G_aux = copy.deepcopy(G_train)\n",
    "    G_aux.remove_edges_from(testing_pos_edges)\n",
    "    train_pos_edges=G_aux.edges()\n",
    "    return G1, G_train, testing_pos_edges, train_graph_filename,G0,train_pos_edges\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_neg_edges(G0, edges_num, seed):\n",
    "    random.seed(seed)\n",
    "    neg_edges = random.sample(G0.edges, edges_num)\n",
    "    return neg_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding(embedding_file_name,species, node_list=None):\n",
    "    dict_club = {}\n",
    "    filename = 'data/'+str(species)+'/'+str(species)+'.csv'\n",
    "    with open(filename,'r',encoding='utf-8')as f:\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        for row in reader:\n",
    "            dict_club[row[0]] = row[1:]\n",
    "    #This model can be obtained in delseq.ipynb\n",
    "    model = KeyedVectors.load_word2vec_format( 'data/'+str(species)+'/'+str(species)+'.txt', binary=False)\n",
    "    seqfeature = {}\n",
    "    with open(filename, 'r',encoding='utf-8-sig') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            row=row[1]\n",
    "            arr1 = np.zeros(model.vector_size)\n",
    "            for x in range(int(len(row) / 3)):\n",
    "                try:\n",
    "                    list1 = model[str(row[x * 3:x * 3 + 3])]\n",
    "                    arr1 += list1\n",
    "                except:\n",
    "                    continue\n",
    "            seqfeature[row] = arr1 / (int(len(row) / 3))\n",
    "\n",
    "    with open(embedding_file_name) as f:\n",
    "        node_num, emb_size = f.readline().split()\n",
    "        embedding_look_up = {}\n",
    "        for line in f:\n",
    "            vec = line.strip().split()\n",
    "            node_id = vec[0]\n",
    "            embeddings = vec[1:]\n",
    "            seq1 = dict_club[node_id]\n",
    "            seq1 = ' '.join(seq1)\n",
    "            emb = [float(x) for x in embeddings]\n",
    "            emb=np.append(emb,seqfeature[seq1])\n",
    "            emb = emb / np.linalg.norm(emb)\n",
    "            emb[np.isnan(emb)] = 0\n",
    "            embedding_look_up[node_id] = list(emb)\n",
    "        assert int(node_num) == len(embedding_look_up)\n",
    "        f.close()\n",
    "        return embedding_look_up\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_training(args, train_graph_filename):\n",
    "    g = read_for_OpenNE(train_graph_filename)\n",
    "    _embedding_training(args, G_=g)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _embedding_training(args, G_=None):\n",
    "    model = node2vec.Node2vec(graph=G_, path_length=64,\n",
    "                              num_paths=32, dim=100,\n",
    "                              workers=8, p=1, q=1, window=10)\n",
    "    model.save_embeddings(args.output)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protein",
   "language": "python",
   "name": "protein"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
